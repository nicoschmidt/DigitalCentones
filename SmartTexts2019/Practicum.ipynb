{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practicum.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicoschmidt/DigitalCentones/blob/master/SmartTexts2019/Practicum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1je_UIgTFDSg",
        "colab_type": "text"
      },
      "source": [
        "# Smart Texts 2019 Practicum May 27th:\n",
        "# Christus Patiens and the opportunities for Digital Reading\n",
        "\n",
        "Welcome to the Smart Texts practicum! Today we will investigate the possibilities of computer-aided intertextual reading.\n",
        "In this session you will get to know some techniques to handle a digital version of the Greek cento Christus Patiens from late antiquity by Gregorius Nazianzenus. You can have a look at a digital version, an edition by Johann Georg Brambs from 1885 in the Scaife Viewer: https://scaife.perseus.org/reader/urn:cts:greekLit:tlg2022.tlg003.opp-grc1:1.1-1.30/\n",
        "\n",
        "It is also available as TEI formatted xml file on GitHub (along with many other texts!) in the repository of the ***OpenGreekAndLatin*** project: https://github.com/OpenGreekAndLatin/First1KGreek/blob/master/data/tlg2022/tlg003/tlg2022.tlg003.opp-grc1.xml\n",
        "\n",
        "We will make use of this formatted text for analyzing it with our software. As you have learned in the seminar today, a Cento is a patchwork poem made of many parts, lines or single words from other (source) texts. In the case of Christus Patiens the source texts to a large part are chosen from tragedies by Euripides, such as Medea, Bacchae and others.\n",
        "\n",
        "We will use the alignment algorithm discussed during today's seminar - Smith-Waterman - to find for each line of the Christus Patiens the corresponding (matching) text in the source tragedies. For time reasons and because of limited availability of the source text as formatted xml files, we will restrict our analysis to the first 100 lines of the Christus Patiens and match them with the first 48 lines of Euripides' *Medea*.\n",
        "\n",
        "As with most algorithms, the Smith-Waterman algorithm comes with some parameters which needs to be tuned in order to produce meaningful results. In the coming exercises you will play around with those parameters to tweak the algorithm. You will compare your results to the matches found by an expert researcher in this field (Tuillier 1969).\n",
        "\n",
        "If you look for a more advanced programming exercise, you can even work on extensions of the alignment program - during this practicum or continue your work afterwards in a student project.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcdxFqc6n-H0",
        "colab_type": "text"
      },
      "source": [
        "# 1) Get to know the data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQGCaBXVdBpM",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Prepare code\n",
        "Steps:\n",
        "- get code and data files from GitHub\n",
        "- import code and other libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF-HX9fVi7R0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!([ -d DigitalCentones ]) && rm -r DigitalCentones\n",
        "!git clone https://github.com/nicoschmidt/DigitalCentones\n",
        "\n",
        "from DigitalCentones.smith_waterman import SmithWaterman\n",
        "from DigitalCentones.alignment import *\n",
        "from IPython.display import HTML\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EIv-_g3HFWi",
        "colab_type": "text"
      },
      "source": [
        "## Load Christus Patiens and Medea text files\n",
        "Steps:\n",
        "- copy xml file of Christus Patiens from GitHub repository ***First1KGreek*** by the ***OpenGreekAndLatin*** project\n",
        "- parse the xml file\n",
        "- remove preface lines\n",
        "- load first 48 lines from Medea as plain text (no xml available yet :( )\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqH1epQTnXau",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 1.1: Get familiar with the text\n",
        "Have a look at the [xml file](https://github.com/OpenGreekAndLatin/First1KGreek/blob/master/data/tlg2022/tlg003/tlg2022.tlg003.opp-grc1.xml).\n",
        "It contains all lines of the poem with lots of meta information, in the header as well as along each page:\n",
        "- editorial information\n",
        "- information about online edition\n",
        "- line numbers\n",
        "- footnotes\n",
        "\n",
        "We parse the lines like this:\n",
        "```\n",
        "<l n=\"1\">Εἴθ᾿ ὤφελ’ ἐν λειμῶνι μηδ’ ἕρπειν ὄφις,</l>\n",
        "\n",
        "```\n",
        "Have a look at the function [load_xml(fname) on line 1667 of alignment.py](https://github.com/nicoschmidt/DigitalCentones/blob/3c1df2ce56f5d4776be395dd62773e70b715cd88/alignment.py#L167).\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m905nMBlHKhj",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 1.2: Get familiar with the data structures\n",
        "The lines are loaded in a list-like structure.\n",
        "\n",
        "While parsing, some pre-processing is done that will help with finding alignments:\n",
        "- punctuation removed\n",
        "- lower case\n",
        "- diacritics removed\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPP6usf7jSh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get Christus Patiens xml file (if not present)\n",
        "!([ ! -f tlg2022.tlg003.opp-grc1.xml ]) && wget https://raw.githubusercontent.com/OpenGreekAndLatin/First1KGreek/master/data/tlg2022/tlg003/tlg2022.tlg003.opp-grc1.xml\n",
        "lines_chr_pat = load_xml('tlg2022.tlg003.opp-grc1.xml')\n",
        "for i in range(30, len(lines_chr_pat)):\n",
        "    lines_chr_pat[i].no = -29+i # hack to re-number lines\n",
        "lines_chr_pat = lines_chr_pat[30:100]\n",
        "print('Christus Patiens:', lines_chr_pat[:3],'\\n\\n')\n",
        "\n",
        "lines_medea = load_plain_text('DigitalCentones/data/Medea-48.txt', 'Medea', 'Medea', 'Euripides')\n",
        "print('Medea:', lines_medea[:3], '\\n\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFOadldspj3N",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Print all characters with diacritics**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS9YtJd8mDo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print all characters in the corpus:\n",
        "alphabet = np.unique([c for lines in [lines_chr_pat, lines_medea] for line in lines for c in line.text])\n",
        "print('ID, Character, Name')\n",
        "for a in alphabet:\n",
        "    print('{} \"{}\" {}'.format(hex(ord(a)), a, unicodedata.name(a, 'not defined')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIqrnXPhqRM2",
        "colab_type": "text"
      },
      "source": [
        "**Print all characters without diacritics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac4FEVB7qUyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alphabet_no_diacritics = np.unique([c for lines in [lines_chr_pat, lines_medea] for line in lines for c in line.text_no_diacritics])\n",
        "print('ID, Character, Name')\n",
        "for a in alphabet_no_diacritics:\n",
        "    print('{} \"{}\" {}'.format(hex(ord(a)), a, unicodedata.name(a, 'not defined')))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qACHAjrsXhk",
        "colab_type": "text"
      },
      "source": [
        "## Load all Matches found by Tuillier 1969\n",
        "As a baseline we compare our alignment results later on to the matches found by an expert researcher in the field, Andre Tuillier, who, in his edition of the Christus Patiens from 1969, listed down all the corresponding lines he found relevant. Thanks to Lena, who analized these correspondences during her PhD thesis, we have these correspondences as a [machine-readable text file](https://github.com/nicoschmidt/DigitalCentones/blob/master/data/ChristusPatiens_Tulliers_matches.csv) and can load them here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYeEWo7YqnbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input file is a text file with one header row and remaining rows structured as\n",
        "# '<target_line_number>,<source_work_number>,<source_work_line_number>...\\n'\n",
        "line_to_line_map = np.loadtxt('DigitalCentones/data/ChristusPatiens_Tulliers_matches.csv', int, delimiter=',', skiprows=1, usecols=[0,1,2])\n",
        "\n",
        "# These are all matched works Toullier found\n",
        "source_work_names = ['Agamemnon',\n",
        "                     'Prometheus',\n",
        "                     'Alkestis',\n",
        "                     'Andromache',\n",
        "                     'Bakchen',\n",
        "                     'Hekabe',\n",
        "                     'Helena',\n",
        "                     'Hippolytos',\n",
        "                     'Iphigenie in Aulis',\n",
        "                     'Iphigenie in Tauris',\n",
        "                     'Medea',\n",
        "                     'Orestes',\n",
        "                     'Ph\\\"onikerinnen',\n",
        "                     'Rhesos',\n",
        "                     'Troerinnen',\n",
        "                     'Ilias',\n",
        "                     'Alexandra']\n",
        "\n",
        "# store map as a dictionary with target_line_number as keys and tuples (<source_work_id>, <source_work_number>) as values \n",
        "line_to_line_map = dict([(target_line_no,(source_work_names[source_work_id-1], source_line_id)) for target_line_no, source_work_id, source_line_id in line_to_line_map])\n",
        "for k in list(line_to_line_map)[:50]:\n",
        "    print('{}: {}'.format(k, line_to_line_map[k]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhrfF4fudTuC",
        "colab_type": "text"
      },
      "source": [
        "# 2) Compare alignment schemes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udxwc4s5dbI6",
        "colab_type": "text"
      },
      "source": [
        "## The expert's results\n",
        "First we go through the lines listed by Tuillier to find exact line-to-line alignments and visualize them.\n",
        "\n",
        "With our automatic alignment search later on, we seek to get as close as possible to these matches **without knowing anything about ancient Greek tragedies!** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6jjU4s6uNkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find matches by searching in given line-to-line map\n",
        "smith_waterman = SmithWaterman(match_score=2,\n",
        "                               mismatch_score=-1,\n",
        "                               gap_score=-1,\n",
        "                               n_max_alignments=1,\n",
        "                               min_score_treshold=0)\n",
        "alignments_outfile = 'alignments_word-based_Toullier'\n",
        "target_lines = lines_chr_pat\n",
        "source_lines_dict = {lines_medea[0].work_id:lines_medea}\n",
        "alignments = find_line_to_line_alignments(target_lines, source_lines_dict, smith_waterman.align, 3, lambda line:line.text_no_diacritics.split(' '), line_to_line_map)\n",
        "save_alignments_html(alignments, target_lines, source_lines_dict, alignments_outfile, lambda line:line.text_raw.split(' '), 4)\n",
        "HTML(filename='./'+ alignments_outfile + '.html')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXJL9-ceEb-N",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2.1: The Smith-Waterman Algorithm\n",
        "Check out the code at https://github.com/nicoschmidt/DigitalCentones/blob/master/smith_waterman.py and try to understand the basic working of the alignment function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1N7i-D3x6-A",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2.2: Find character-based line-to-line alignments with diacritics\n",
        "Now we use the Smith-Waterman algorithm to find all alignments automatically.\n",
        "Run the following code and inspect the ouput.\n",
        "\n",
        "Where does it differ? Where does it find good/bad alignments?\n",
        "\n",
        "Tweak the scores for match, mismatch and gaps and try to find a good setting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmNvsOfHw4P-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smith_waterman = SmithWaterman(match_score=2,\n",
        "                               mismatch_score=-1,\n",
        "                               gap_score=-1,\n",
        "                               n_max_alignments=1,\n",
        "                               min_score_treshold=0)\n",
        "line_form_func = lambda line:line.text # we use the lower-case text with diacritics\n",
        "alignments_outfile = 'alignments_character-based_with_diacritics'\n",
        "target_lines = lines_chr_pat\n",
        "source_lines_dict = {lines_medea[0].work_id:lines_medea}\n",
        "alignments = find_line_to_line_alignments(target_lines, source_lines_dict, smith_waterman.align, 3, line_form_func)\n",
        "save_alignments_html(alignments, target_lines, source_lines_dict, alignments_outfile, line_form_func)\n",
        "HTML(filename='./'+ alignments_outfile + '.html')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY3-k-Coy7FV",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2.3: Find character-based line-to-line alignments without diacritics\n",
        "Now we change the input strings to be text without diacritics (have a look at the line_form_func and Exercise 1.2 as well as [the data structure](https://github.com/nicoschmidt/DigitalCentones/blob/e51e1100201cc08971d1c742adcc44275c5359e1/alignment.py#L75)).\n",
        "\n",
        "Run the following code and inspect the ouput.\n",
        "\n",
        "Where does it differ? Where does it find good/bad alignments?\n",
        "\n",
        "Tweak the scores for match, mismatch and gaps and try to find a good setting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiJYrxYtyOt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smith_waterman = SmithWaterman(match_score=2,\n",
        "                               mismatch_score=-1,\n",
        "                               gap_score=-1,\n",
        "                               n_max_alignments=1,\n",
        "                               min_score_treshold=0)\n",
        "line_form_func = lambda line:line.text_no_diacritics\n",
        "alignments_outfile = 'alignments_character-based_without_diacritics'\n",
        "target_lines = lines_chr_pat\n",
        "source_lines_dict = {lines_medea[0].work_id:lines_medea}\n",
        "alignments = find_line_to_line_alignments(target_lines, source_lines_dict, smith_waterman.align, 3, line_form_func)\n",
        "save_alignments_html(alignments, target_lines, source_lines_dict, alignments_outfile, line_form_func, 4)\n",
        "HTML(filename='./'+ alignments_outfile + '.html')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyxKZq2zzEQ_",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2.4: Find word-based line-to-line alignments without diacritics\n",
        "Instead of treating the lines as sequences of characters, we can also treat them as sequences of words and do the matching on a word-level\n",
        "\n",
        "Run the following code and inspect the ouput.\n",
        "\n",
        "Where does it differ? Where does it find good/bad alignments? What about processing speed?\n",
        "\n",
        "Tweak the scores for match, mismatch and gaps and try to find a good setting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9DxbKThzKub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smith_waterman = SmithWaterman(match_score=2,\n",
        "                               mismatch_score=-1,\n",
        "                               gap_score=-1,\n",
        "                               n_max_alignments=1,\n",
        "                               min_score_treshold=0)\n",
        "line_form_func = lambda line:line.text_no_diacritics.split(' ')\n",
        "alignments_outfile = 'alignments_word-based_without_diacritics'\n",
        "target_lines = lines_chr_pat\n",
        "source_lines_dict = {lines_medea[0].work_id:lines_medea}\n",
        "alignments = find_line_to_line_alignments(target_lines, source_lines_dict, smith_waterman.align, 3, line_form_func)\n",
        "save_alignments_html(alignments, target_lines, source_lines_dict, alignments_outfile, lambda line:line.text_raw.split(' '), 4)\n",
        "HTML(filename='./'+ alignments_outfile + '.html')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk1dfuHtD6oT",
        "colab_type": "text"
      },
      "source": [
        "# 3) Advanced exercises and extensions\n",
        "\n",
        "Now that you got the basic ideas and a feeling for how the algorithm behaves and how parameters affect the outputs, here are some suggestions how to further improve the software.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAjnJXdXNi22",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 3.1: incorporating morphological information\n",
        "Because \n",
        "Have a look at the formatting of the morphology data base files: \n",
        "```\n",
        "<d>\n",
        "  <token>\n",
        "    <word-form-id>1</word-form-id>\n",
        "    <word-form>ἀάατον</word-form>\n",
        "    <word-form-without-diacritics>ααατον</word-form-without-diacritics>\n",
        "    <lemma>ἀάατος</lemma>\n",
        "    <lemma-without-diacritics>ααατος</lemma-without-diacritics>\n",
        "    <morphological-analysis>a-s---fa-</morphological-analysis>\n",
        "    <lemma-id>1</lemma-id>\n",
        "    <translation>not to be injured, inviolable</translation>\n",
        "    <dialect/>\n",
        "  </token>\n",
        "<t>\n",
        "  <i>1</i>\n",
        "  <f>ἀάατον</f>\n",
        "  <b>ααατον</b>\n",
        "  <l>ἀάατος</l>\n",
        "  <e>ααατος</e>\n",
        "  <p>a-s---fa-</p>\n",
        "  <d>1</d>\n",
        "  <s>not to be injured, inviolable</s>\n",
        "  <a/>\n",
        "</t>\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Steps:\n",
        "- load morphological data base from GitHub\n",
        "- Map all words to their lemmatized form\n",
        "- Find alignments using the lemmas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHD4qV61z1lP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download files if not present\n",
        "!([ ! -f MorpheusGreek1-319492.xml ]) && wget https://raw.githubusercontent.com/gcelano/MorpheusGreekUnicode/master/MorpheusGreek1-319492.xml\n",
        "!([ ! -f MorpheusGreek319493-638984.xml ]) && wget https://raw.githubusercontent.com/gcelano/MorpheusGreekUnicode/master/MorpheusGreek319493-638984.xml\n",
        "!([ ! -f MorpheusGreek638985-958476.xml ]) && wget https://raw.githubusercontent.com/gcelano/MorpheusGreekUnicode/master/MorpheusGreek638985-958476.xml\n",
        "morph_xml_fnames = ['MorpheusGreek1-319492.xml',\n",
        "                    'MorpheusGreek319493-638984.xml',\n",
        "                    'MorpheusGreek638985-958476.xml']\n",
        "\n",
        "# load data base\n",
        "morph_dict, max_id = load_morphology(morph_xml_fnames, False)\n",
        "print('{} lemmas loaded'.format(max_id))\n",
        "\n",
        "# add all words of Christus Patiens and Medea that were not in the data base\n",
        "m = max_id\n",
        "max_id = add_lemma_ids(lines_chr_pat, morph_dict, max_id, False)\n",
        "print('{} lemmas added by Christus Patiens'.format(max_id - m))\n",
        "m = max_id\n",
        "max_id = add_lemma_ids(lines_medea, morph_dict, max_id, False)\n",
        "print('{} lemmas added by Medea'.format(max_id - m))\n",
        "print('{} total lemmas'.format(max_id))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBa1ZzqRNl7F",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 3.2: Word count statistics\n",
        "Modify the alignment scoring by introducing a weighted matching score scheme, where frequent (but potentially uninteresting) words get lower match scores and rare, (but potentially interesting words) get higher match scores.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm2rQA_sNnyu",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 3.3: Alternative alignment algorithms\n",
        "Create an alternative alignment function, e.g. by just counting same words in lines to be matched, without taking care of the ordering of words. Does this improve the results? In which situations?"
      ]
    }
  ]
}